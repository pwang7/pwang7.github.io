# 内存顺序（Memory Order）第一部分

内存顺序，通俗地讲，是关于代码编译成机器指令后的执行顺序问题。内存顺序和编译器、硬件架构密切相关。那为什么会产生内存顺序问题呢？有两方面原因：
一方面，编译器为了优化程序性能，不会完全按照开发者写的代码的顺序来生成机器指令；
另一方面，在程序运行时，为了提高性能，CPU也不完全按照程序的指令顺序执行，比如Tomasulo算法。

对于大部分开发者而言，在写单线程程序，或者基于锁（Mutex）或信号量（Semaphore）之类编程框架提供的同步元语写多线程程序的时候，并不需要关心内存顺序的问题。
这是因为编译器和硬件架构保证了，虽然指令执行顺序可能跟开发者写的代码的顺序不一致，但是执行后的结果是一样的，即语义一致。
换句话讲，编译器和硬件架构提供了一层抽象用以屏蔽内存顺序问题，保证代码和编译出来的程序执行语义一致。这样一方面提高程序性能，一方面让开发者不用关心底层细节。
这种为了便于理解和使用而提出一层抽象以屏蔽底层复杂细节的方法，在各个学科中比比皆是。
类比经典力学和相对论，在远低于光速的运动中，适用经典力学，在接近或达到光速的运动中，适用相对论而不适用经典力学；
经典力学和相对论之间，有一层基于物体运动速度的抽象，速度远低于光速，抽象成立，速度接近或达到光速，抽象被打破。
同样道理，编译器和硬件架构提供了一层抽象用以屏蔽内存顺序问题。
对于大部分开发者而言，写单线程程序，或基于编程框架提供的同步元语写多线程程序的时候，编译器和硬件架构提供的抽象成立，无需考虑内存顺序问题；
当无锁化编程的时候，多线程并发访问（或读或写）共享数据的时候使用原子操作，而不是基于锁互斥访问数据，这时编译器和硬件架构提供的抽象被打破，开发者必须考虑内存顺序问题。

内存顺序问题涉及编译器和硬件架构的很多细节，我尝试用对于大部分开发者来说浅显易懂的语言来描述内存顺序问题，尽可能避免编译器和硬件架构的实现细节，以便于大家理解。
内存顺序跟内存模型和原子操作这两个概念非常相关，先介绍这两个概念，然后以C++11为例讲解内存顺序问题。

## 内存模型

内存模型是编程语言对程序运行时的抽象，即内存被多个程序（进程和线程）共享，程序对内存的访问是无法预知的。
通俗地讲（忽略单CPU场景，仅考虑多CPU场景），内存顺序相关的内存模型指的是多个CPU共享内存，CPU并发随机访问内存，
或从内存加载数据（Load）或把数据写入内存（Store）。
Load和Store是机器指令（或汇编语言）的术语，其实就是读（Read）操作和写（Write）操作。
内存模型屏蔽了很多硬件的细节，比如CPU的寄存器、缓存等等
（内存顺序相关的内存模型主要关注并发场景，而寄存器和缓存对CPU来说是独享的，访问寄存器和缓存不存在并发）。
内存模型比较好理解，每个开发者或多或少都接触到内存模型。

有了内存模型这一层抽象，那么内存顺序问题可以等价于读操作和写操作的执行顺序问题，因为内存模型里CPU对内存的访问只有读和写两种操作。
开发者在写代码时，代码的先后顺序往往约定了对内存访问的先后顺序的，即使访问的不是同一个内存地址。看下面的单线程代码示例：
```
int x, y = 0;
x = y + 1;
y = 2;
```
这段代码定义了两个整数，`x`和`y`，并对`y`初始化赋值为`0`，然后给`x`赋值的时候用到`y`的值，之后再给`y`赋值。
看上去对`y`的写操作必须在对`x`的写操作之后，但是改写上述代码片段如下：
```
int x, y = 0;
int tmp;
tmp = y;
y = 2;
x = tmp + 1;
```
增加了变量`tmp`之后，首先把`y`的值付给`tmp`，然后就可以先对`y`赋新值，再给`x`赋值。对`x`和`y`来说，这两段程序的执行结果是等价的。
变量`tmp`在这里可以理解为是CPU的寄存器，有了寄存器的帮助，代码里的读操作和写操作先后顺序可能被改变。

再考虑多线程的情况，把对`x`的写操作和对`y`的写操作放在不同的线程里：
```
int x, y = 0;

void thread_func1() {
    x = y + 1;
}

void thread_func2() {
    y = 2;
}
```
可以看出，`x`会有多种结果，取决于两个线程的执行顺序，这就跟之前单线程的执行结果不一致了。

通俗地讲，内存顺序就是开发者要求编译器和硬件架构对读写操作执行顺序的规约。
上面的例子展示了对两个写操作的顺序问题。推而广之，内存顺序包含四种情况：

|读读|读写|
|---|---|
|写读|写写|

即，读操作与读操作、读操作与写操作、写操作与读操作、写操作与写操作，四种情况下的指令执行顺序问题（不论是否读写同一个内存地址）。
开发者可以要求编译器和硬件架构在上述四种情况下分别做出规约，即：
* 读读，读操作之后的读操作，之间的顺序不能改变；
* 读写，读操作之后的写操作，之间的顺序不能改变；
* 写读，写操作之后的读操作，之间的顺序不能改变；
* 写写，写操作之后的写操作，之间的顺序不能改变。

## 原子操作

原子操作要么执行成功，要么尚未开始执行，不存在中间状态。
原子操作是要靠底层硬件架构来实现，只有硬件架构的某些指令才能保证原子操作，比如Compare and Swap（CAS）指令。
编程语言基于硬件架构的原子操作指令封装了一些原子类型以及原子操作（函数调用），以方便开发者使用。

另外，当CPU读写地址对齐的内存数据的时候，有可能是原子操作。
比如32位CPU，访问一个32位整数，如果这个整数的地址是4的倍数，即内存地址对齐，那么访问操作就是原子的，
即CPU执行一条指令（在一个指令周期内）读取或写入这个整数；
但是如果这个整数的地址不是4的倍数，那CPU还是要两次访问（执行两条指令）才能读取或写入这个整数，在这两次访问中间CPU有可能被其他程序抢占。
由于在编程的时候不能假设数据的内存地址一定是4的倍数，所以开发者要默认每一条代码语句都不是原子操作，除非明确使用原子操作。

## C++的内存顺序

下面以C++语言为例，介绍开发者如何对内存顺序做出规约，即要求编译器和硬件架构保证按照期望的顺序来执行指令。

C++11提供了`Atomic`泛型，用于封装原子类型和原子操作。C++还定义了`atomic_int`、`atomic_long`、`atomic_bool`等类型，方便开发者直接使用。
下面的代码片段给出了Atomic泛型的定义，以及三个`Atomic`泛型的方法（为了便于读者理解，方法的定义略有删节）：
```
template <class T> struct atomic;
...
T load (memory_order sync) const noexcept;
void store (T val, memory_order sync) noexcept;
bool compare_exchange_strong (T& expected, T val,
        memory_order sync) noexcept;
...
```
上面`Atomic`泛型的方法里有个输入参数`sync`的类型`memory_order`，用于规约`Atomic`泛型方法的内存顺序。
`memory_order`在C++11里定义为枚举类型，共有六个值，是C++11定义的内存顺序类型，可供开发者使用：
```
typedef enum memory_order {
    memory_order_relaxed,
    memory_order_consume,
    memory_order_acquire,
    memory_order_release,
    memory_order_acq_rel,
    memory_order_seq_cst
} memory_order;
```
限于篇幅，这里只介绍`memory_order_acquire`（简称Acquire）和`memory_order_release`（简称Release）这两种内存顺序，后续再介绍C++的其他内存顺序。
下表给出了Acquire和Release的语义：

|内存顺序|语义|
|---|---|
|Acquire|读读、读写|
|Release|写写、读写|

即，Acquire要求读操作之后的读操作、读操作之后的写操作，这两种情况下的指令顺序不能改变；
Release要求写操作之后的写操作、读操作之后的写操作，这两种情况下的执行顺序不能改变
（对于Release的语义，更常见的说法是写操作之前的读操作、写操作之前的读操作，这两种情况下的执行顺序不能改变）。

先给个Acquire和Release的例子：
```
#include <atomic>
#include <iostream> 
#include <vector>

std::atomic_int indicator (0); // 初始值为零
std::vector<int> vec;

void thread_func1() {
    for (int i = 1; i <= 10000; i++) {
        vec.push_back(i);
    }

    // 通知thread_func2可以读取vec了
    indicator.store(1, // 写操作
            std::memory_order_release); 
}

void thread_func2() {
    int ready;

    // 等待thread_func1完成vec的插入
    do {
        ready = indicator.load( // 读操作
                std::memory_order_acquire);
    } while (ready == 0);

    for i in vec {
        std::cout << i << std::endl;
    }
}
```
上述代码定义了一个全局原子整数变量`indicator`和一个全局数组`vec`，
线程函数`thread_func1`在数组`vec`完成插入操作后，用`indicator`通知线程函数`thread_func2`可以读取`vec`的数据了。
特别要注意两个原子操作`indicator.store()`和`indicator.load()`的内存顺序，
为什么`indicator.store()`用Release语义，而`indicator.load()`用Acquire语义呢？

先考虑`indicator.store()`的Release语义。
线程函数`thread_func1`先把数组`vec`的数据准备好（给`vec`插入数据），然后调用`indicator.store()`把`indicator`的值改为`1`，
`indicator.store()`的执行顺序不允许改变，绝不能是先调用`indicator.store()`再给`vec`插入数据。
也就是说，对`indicator`的写操作`indicator.store()`之前的操作（包括给`vec`插入数据），都必须保证在`indicator.store()`之前执行，符合Release的语义。

再看`indicator.load()`的Acquire语义。
线程函数`thread_func2`先是不停地调用`indicator.load()`读取`indicator`的值，检查是否不等于零，如果不为零，则读取数组`vec`的数据，
`indicator.load()`的执行顺序不允许改变，绝不能是先读取`vec`的数据，再读取`indicator`的值。
也就是说，对`indicator`的读操作`indicator.load()`之后的操作（包括读取`vec`的数据），都必须保证在`indicator.load()`之后执行，符合Acquire的语义。

简单来说，对于原子写操作要求Release语义，对于原子读操作要求Acquire语义。
有些文章把Acquire和Release比作是对一个锁进行加锁和解锁操作，个人认为这样的比喻不是很准确。
准确的讲，Release和Acquire这类内存顺序，跟锁和信号量的抽象层面不一样，内存顺序比锁和信号量更底层，可以用原子操作和内存顺序来实现锁和信号量。
`indicator.store()`和`indicator.load()`分别采用Release和Acquire语义，定义了两个线程间的同步通知关系（Synchronize with），
即`indicator`变量用于指示数据`vec`是否准备好。这种同步通知关系不是静态规约好的，而是在程序运行时动态检查。
此外，这两个线程之间的这种同步通知关系的正确与否，强烈依赖于`indicator.store()`和`indicator.load()`的执行顺序，
如果把`indicator.load()`和`indicator.store()`的内存顺序改成其他语义，就有可能无法保证同步通知关系的正确。
因此Release不是解锁操作，Acquire也不是加锁操作，这跟锁的互斥机制不一样。

限于篇幅，我后续再对C++的其他内存顺序和同步通知机制做详细介绍。
